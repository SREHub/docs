阿里sunfire监控系统
下发拓扑任务：configDB->Brain->reduce->map->agent
收集统计日志：agent(收集)->map(计算)->reduce(聚合)->hbase
preload提前注册
1.提前发现故障机器，并屏蔽掉。
2.输入共享，合并任务。
pull 拉取的方式
1.主动权在server端，出错可控。
2.降低用户开销
如何做到快速的日志读取？
agent零拷贝，不经过cpu处理直接经过socket传输，优势：快。劣势：没有压缩等，数据量大。
稳定性：
下发失败，重试即可。
下发成功，执行失败怎么搞？
Brain生成任务之后，就安装成功了一个Reduce,Brain就回去守护这个Reduce。
也就是上游会确保下游执行成功，不成功则换个节点继续方式。
agent进行日志拉取的时候，也有自我保护逻辑，防止资源不够用。

统计值优先：应对业务流水日志很多的情况下。

configDB中配置了监控项，定义日志采集的位置、处理和计算方式等。
Brain定期从configDB中读取数据，生成拓扑任务，下发到Reduce上面，逐级下发。

日志采集的时候引入了齐全度的概念，表示agent成功获取到了多少个节点的日志信息，来作为业务流量涨跌的一个参考。
因为日志的获取是采用pull的方式，同时监控对时间也有要求，所以在规定的超时时间内拉取日志失败，那么就直接返回
结果。




我们的pp监控是怎么做的？
其实也相当于有提前注册的逻辑，把需要的值告诉平台，平台在db中生成对应的字段。
nginx的日志上报模块把日志上报到spartaproxy，spartaproxy接收到数据后发送给monitorserver。
monitorserver进行日志的拆分上报到DB里面(把需要监控的对应的value都取出来并写入到DB对应的字段)
DB里面的数据进行统计展示。
其实我们的更像是传统的日志监控系统：
agent上报->kafka->jstorm->DB->web
